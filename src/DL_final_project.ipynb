{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR3YdnsQTtOj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from functools import reduce\n",
        "from operator import __add__\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "        self.kernel_sizes = (3, 3)\n",
        "        self.conv_padding = reduce(__add__, \n",
        "            [(k // 2 + (k - 2 * (k // 2)) - 1, k // 2) for k in self.kernel_sizes[::-1]])\n",
        "\n",
        "    def forward(self, input):\n",
        "        residual = input\n",
        "        x = nn.ZeroPad2d(self.conv_padding)(input)\n",
        "        x = self.bn1(self.conv1(x))\n",
        "        x = self.prelu(x)\n",
        "        x = nn.ZeroPad2d(self.conv_padding)(input)\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        return x\n",
        "\n",
        "class NoiseGenerator(nn.Module):\n",
        "    def __init__(self, block, num_of_resblock=5, input_channels=3):\n",
        "        super(NoiseGenerator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(input_channels, 3, kernel_size=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.layers = self._make_layer(block, num_of_resblock)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(input_channels, 3, kernel_size=3, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(3)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(input_channels, 3, kernel_size=3, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(3)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.kernel_sizes = (3, 3)\n",
        "        self.conv_padding = reduce(__add__, \n",
        "            [(k // 2 + (k - 2 * (k // 2)) - 1, k // 2) for k in self.kernel_sizes[::-1]])\n",
        "\n",
        "    def _make_layer(self, block, num_of_resblock):\n",
        "        layers = []\n",
        "        for i in range(num_of_resblock):\n",
        "          layers.append(block(in_channels=3, out_channels=3))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = nn.ZeroPad2d(self.conv_padding)(input)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        residual = x\n",
        "\n",
        "        x = self.layers(x)\n",
        "\n",
        "        x = nn.ZeroPad2d(self.conv_padding)(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        comb = x + residual\n",
        "\n",
        "        comb = nn.ZeroPad2d(self.conv_padding)(comb)\n",
        "        comb = self.conv3(comb)\n",
        "        comb = self.bn3(comb)\n",
        "        comb = self.relu3(comb)\n",
        "\n",
        "        return comb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NoiseGenerator(ResBlock)\n",
        "print(model)\n",
        "input = torch.ones([4,3,28,28])\n",
        "output = model(input)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6TvN2vsWXXX",
        "outputId": "ec8a77a7-0951-41a9-a72b-a73570c5295b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NoiseGenerator(\n",
            "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU(inplace=True)\n",
            "  (layers): Sequential(\n",
            "    (0): ResBlock(\n",
            "      (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (1): ResBlock(\n",
            "      (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (2): ResBlock(\n",
            "      (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (3): ResBlock(\n",
            "      (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (4): ResBlock(\n",
            "      (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU(inplace=True)\n",
            "  (conv3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU(inplace=True)\n",
            ")\n",
            "torch.Size([4, 3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from functools import reduce\n",
        "from operator import __add__\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, stride=2):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 3, stride=stride, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.bn(self.conv(input))\n",
        "        # print(x.shape)\n",
        "        x = self.lrelu(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, block, input_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(input_channels, 3, kernel_size=3, padding='same', bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(3)\n",
        "        self.relu1 = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.channels = [64, 128, 128, 256, 256, 512, 512]\n",
        "        self.strides = [2, 1, 2, 1, 2, 1, 2]\n",
        "        self.layers = self._make_layer(block, self.channels, self.strides)\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "        self.dense = nn.LazyLinear (out_features=1024)\n",
        "        self.relu2 = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.dense2 = nn.Linear(1024, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, chennels_num, strides):\n",
        "        layers = []\n",
        "        layers.append(block(in_channels=3, out_channels=chennels_num[0], stride = strides[0]))\n",
        "        for i in range(1,len(chennels_num)-1):\n",
        "          layers.append(block(in_channels=chennels_num[i-1], out_channels=chennels_num[i], stride = strides[i]))\n",
        "        layers.append(block(in_channels=chennels_num[-2], out_channels=chennels_num[-1], stride = strides[-1]))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        print(x.shape)\n",
        "\n",
        "        x = self.layers(x)\n",
        "        print(x.shape)\n",
        "        x = self.flat(x)\n",
        "        x = self.dense(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.sig(x)\n",
        "\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "JRdg-0gRYAgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Discriminator(ConvLayer)\n",
        "print(model)\n",
        "input = torch.ones([4,3,64,64])\n",
        "output = model(input)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9pb6IdWg777",
        "outputId": "92a77238-8bf5-4727-eaee-a61d747719a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
            "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): LeakyReLU(negative_slope=0.2)\n",
            "  (layers): Sequential(\n",
            "    (0): ConvLayer(\n",
            "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (1): ConvLayer(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (2): ConvLayer(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (3): ConvLayer(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (4): ConvLayer(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (5): ConvLayer(\n",
            "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (6): ConvLayer(\n",
            "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            "  (dense): LazyLinear(in_features=0, out_features=1024, bias=True)\n",
            "  (relu2): LeakyReLU(negative_slope=0.2)\n",
            "  (dense2): Linear(in_features=1024, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n",
            "torch.Size([4, 3, 64, 64])\n",
            "torch.Size([4, 64, 31, 31])\n",
            "torch.Size([4, 128, 29, 29])\n",
            "torch.Size([4, 128, 14, 14])\n",
            "torch.Size([4, 256, 12, 12])\n",
            "torch.Size([4, 256, 5, 5])\n",
            "torch.Size([4, 512, 3, 3])\n",
            "torch.Size([4, 512, 1, 1])\n",
            "torch.Size([4, 512, 1, 1])\n",
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate generator and discriminator\n",
        "generator = NoiseGenerator(ResBlock)\n",
        "discriminator = Discriminator(ConvLayer)\n",
        "forward = DDPM_forward()\n",
        "reverse = DDPM_reverse()\n",
        "\n",
        "# Specify loss functions\n",
        "gan_loss = nn.BCELoss()\n",
        "aux_loss = nn.MSELoss()  # Change to the appropriate loss function for your task\n",
        "\n",
        "# Set up optimizers\n",
        "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
        "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for Anomaly, Normal in dataloader: #normal 不夠的話請用data augmentation補充到跟所有anomaly相同的數量(或是刪掉幾張anomaly)\n",
        "\n",
        "        # ============= setting ==========\n",
        "        batch_size = Anomaly.size(0)\n",
        "\n",
        "        # Generate fake images\n",
        "        generated_noise = generator(Anomaly)\n",
        "        Noised_anomaly = generated_noise + Anomaly\n",
        "\n",
        "        # Generate noised normal images\n",
        "        Noised_normal = forward(Normal)\n",
        "\n",
        "        # Generate Denoised images\n",
        "        Denoised_normal = reverse(Noised_normal)\n",
        "        Denoised_anomaly = reverse(Noised_anomaly)\n",
        "\n",
        "\n",
        "        # =========== Training ==========\n",
        "        # Train the discriminator\n",
        "        discriminator_optimizer.zero_grad()\n",
        "        \n",
        "        real_labels = torch.ones(batch_size, 1)\n",
        "        fake_labels = torch.zeros(batch_size, 1)\n",
        "        \n",
        "        real_outputs = discriminator(Noised_anomaly)\n",
        "        fake_outputs = discriminator(Noised_normal)\n",
        "        \n",
        "        discriminator_loss = gan_loss(real_outputs, real_labels) + gan_loss(fake_outputs, fake_labels)\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "        \n",
        "        # Train the generator\n",
        "        generator_optimizer.zero_grad()\n",
        "        \n",
        "        fake_outputs = discriminator(Noised_anomaly)\n",
        "        \n",
        "        generator_loss = gan_loss(fake_outputs, real_labels)\n",
        "        ## generator_loss.backward()\n",
        "        ## generator_optimizer.step()\n",
        "        \n",
        "        # Compute auxiliary loss\n",
        "        auxiliary_loss = aux_loss(Denoised_normal, Denoised_anomaly)  # Modify according to your task\n",
        "        \n",
        "        # Update generator parameters again with auxiliary loss\n",
        "        ## generator_optimizer.zero_grad()\n",
        "        (generator_loss + auxiliary_loss).backward()\n",
        "        generator_optimizer.step()\n",
        "        \n",
        "        # Print losses or other metrics\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Generator Loss: {generator_loss.item()}, \"\n",
        "              f\"Discriminator Loss: {discriminator_loss.item()}, Auxiliary Loss: {auxiliary_loss.item()}\")"
      ],
      "metadata": {
        "id": "eTMhFf1ag_Fy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}